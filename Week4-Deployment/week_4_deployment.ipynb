{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092e7488",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "In this homework, we'll deploy the ride duration model in batch mode. Like in homework 1, we'll use the Yellow Taxi Trip Records dataset. \n",
    "\n",
    "You'll find the starter code in the [homework](homework) directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a549a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1685023709438/work\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f16215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/zatoichi/anaconda3/envs/mlops:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "scikit-learn              1.2.2            py39hc236052_2    conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "!conda list scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfa5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b402339",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./homework/model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4808de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39108720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f921b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da0e6767",
   "metadata": {},
   "source": [
    "## Q1. Notebook\n",
    "\n",
    "We'll start with the same notebook we ended up with in homework 1.\n",
    "We cleaned it a little bit and kept only the scoring part. You can find the initial notebook [here](homework/starter.ipynb).\n",
    "\n",
    "Run this notebook for the February 2022 data.\n",
    "\n",
    "What's the standard deviation of the predicted duration for this dataset?\n",
    "\n",
    "* **5.28**\n",
    "* 10.28\n",
    "* 15.28\n",
    "* 20.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e6cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "month = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf9fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year:04}-{month:02}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a293111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc02acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(y_pred.std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1e83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f8d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b1c718",
   "metadata": {},
   "source": [
    "## Q2. Preparing the output\n",
    "\n",
    "Like in the course videos, we want to prepare the dataframe with the output. \n",
    "\n",
    "First, let's create an artificial `ride_id` column:\n",
    "\n",
    "```python\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "```\n",
    "\n",
    "Next, write the ride id and the predictions to a dataframe with results. \n",
    "\n",
    "Save it as parquet:\n",
    "\n",
    "```python\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "```\n",
    "\n",
    "What's the size of the output file?\n",
    "\n",
    "* 28M\n",
    "* 38M\n",
    "* 48M\n",
    "* **58M**\n",
    "\n",
    "__Note:__ Make sure you use the snippet above for saving the file. It should contain only these two columns. For this question, don't change the\n",
    "dtypes of the columns and use pyarrow, not fastparquet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3017a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ded6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[['ride_id']].copy()\n",
    "df_result['prediction'] = y_pred\n",
    "output_file = f'./predictions/pred_yellow_tripdata_{year:04}-{month:02}.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "122c4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6faff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size is : 57.22 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_size = os.path.getsize(f'predictions/pred_yellow_tripdata_{year:04}-{month:02}.parquet')\n",
    "print(\"File Size is :\", round(file_size/(1024*1024),2),\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92cfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9053321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f9bd4f",
   "metadata": {},
   "source": [
    "## Q3. Creating the scoring script\n",
    "\n",
    "Now let's turn the notebook into a script. \n",
    "\n",
    "Which command you need to execute for that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0af6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3-score.ipynb was created to find the mean riding time for a given month and a year(after 2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d885af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook q3-score.ipynb to script\n",
      "[NbConvertApp] Writing 1711 bytes to q3-score.py\n"
     ]
    }
   ],
   "source": [
    "# To convert q3-score.ipynb into python executable file, the following command was used \n",
    "# jupyter nbconvert --to script <file-to-convert>.ipynb\n",
    "!jupyter nbconvert --to script q3-score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd883674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f32ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a00bb44",
   "metadata": {},
   "source": [
    "## Q4. Virtual environment\n",
    "\n",
    "Now let's put everything into a virtual environment. We'll use pipenv for that.\n",
    "\n",
    "Install all the required libraries. Pay attention to the Scikit-Learn version:\n",
    "it should be `scikit-learn==1.2.2`. \n",
    "\n",
    "After installing the libraries, pipenv creates two files: `Pipfile`\n",
    "and `Pipfile.lock`. The `Pipfile.lock` file keeps the hashes of the\n",
    "dependencies we use for the virtual env.\n",
    "\n",
    "What's the first hash for the Scikit-Learn dependency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebec29",
   "metadata": {},
   "source": [
    "- Open a terminal in the same project folder and run the following code.\n",
    "    \n",
    "     `pip install pipenv` <br>\n",
    "     `pipenv shell` <br>\n",
    "     `pipenv install -r requirements.txt` <br>\n",
    "    \n",
    "    ***After this the necessary libraries are installed from list of libaries in requirements.txt***\n",
    "\n",
    "    ***Pipfile and Pipfile.lock are updated. Open the Pipfile.lock, scroll till the 1st hash of scikit-learn and copy the data and paste it here.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76019e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97191140",
   "metadata": {},
   "source": [
    "***The first hash for scikit-learn dependency in Pipfile.lock is :*** <br>\n",
    "`065e9673e24e0dc5113e2dd2b4ca30c9d8aa2fa90f4c0597241c93b63130d233` <br>\n",
    "OR <br>\n",
    "`\"sha256:065e9673e24e0dc5113e2dd2b4ca30c9d8aa2fa90f4c0597241c93b63130d233\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8186b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c42a9953",
   "metadata": {},
   "source": [
    "## Q5. Parametrize the script\n",
    "\n",
    "Let's now make the script configurable via CLI. We'll create two \n",
    "parameters: year and month.\n",
    "\n",
    "Run the script for March 2022. \n",
    "\n",
    "What's the mean predicted duration? \n",
    "\n",
    "* 7.76\n",
    "* **12.76**\n",
    "* 17.76\n",
    "* 22.76\n",
    "\n",
    "Hint: just add a print statement to your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c2fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data for the month:03 of the year:2022 to predict the mean riding time\n",
      "\n",
      "Predicting...\n",
      "\n",
      "The predicted mean riding time for the month:03 of the year:2022 is 12.76\n"
     ]
    }
   ],
   "source": [
    "# q5-score.py is a copy of the q3-score.py with some modifications for parameterization and for use with docker\n",
    "!python q5-score.py 2022 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958f968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f1260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8556e920",
   "metadata": {},
   "source": [
    "## Q6. Docker container \n",
    "\n",
    "Finally, we'll package the script in the docker container. \n",
    "For that, you'll need to use a base image that we prepared. \n",
    "\n",
    "This is how it looks like:\n",
    "\n",
    "```\n",
    "FROM python:3.10.0-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY [ \"model2.bin\", \"model.bin\" ]\n",
    "```\n",
    "\n",
    "(see [`homework/Dockerfile`](homework/Dockerfile))\n",
    "\n",
    "We pushed it to [`svizor/zoomcamp-model:mlops-3.10.0-slim`](https://hub.docker.com/layers/svizor/zoomcamp-model/mlops-3.10.0-slim/images/sha256-595bf690875f5b9075550b61c609be10f05e6915609ef4ea4ce9797116c99eff?context=repo),\n",
    "which you should use as your base image.\n",
    "\n",
    "That is, this is how your Dockerfile should start:\n",
    "\n",
    "```docker\n",
    "FROM svizor/zoomcamp-model:mlops-3.10.0-slim\n",
    "\n",
    "# do stuff here\n",
    "```\n",
    "\n",
    "This image already has a pickle file with a dictionary vectorizer\n",
    "and a model. You will need to use them.\n",
    "\n",
    "Important: don't copy the model to the docker image. You will need\n",
    "to use the pickle file already in the image. \n",
    "\n",
    "Now run the script with docker. What's the mean predicted duration\n",
    "for April 2022? \n",
    "\n",
    "\n",
    "* 7.92\n",
    "* **12.83**\n",
    "* 17.92\n",
    "* 22.83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a66e0e9",
   "metadata": {},
   "source": [
    "***To build a docker image, use the following script.*** <br>\n",
    "***Ensure that the Dockerfile is in the same folder along with the necessary files and folders referred in the Dockerfile.***<br>\n",
    "***The command is: <br> `docker build -t <<container_image_name>>:<<tag>> .`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a59c02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (12/12) FINISHED                                              \n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 342B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/svizor/zoomcamp-model:mlops-3.  0.0s\n",
      "\u001b[0m\u001b[34m => [1/7] FROM docker.io/svizor/zoomcamp-model:mlops-3.10.0-slim           0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 93B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/7] RUN pip install -U pip                                    0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/7] RUN pip install pipenv                                    0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/7] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/7] COPY [ Pipfile, Pipfile.lock, ./ ]                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/7] RUN pipenv install --system --deploy                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [7/7] COPY [q6-score.py, ./]                                    0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:e340f82146ca10f15855f4173f1a1522a2326a2f8bff3  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/week4_deployment:latest                 0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build -t week4_deployment:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0401af",
   "metadata": {},
   "source": [
    "***To run the docker container with the parameterized inputs, run the following command:<br>***\n",
    "***`docker run -it <<container_image_name>>:<<tag>>  <<input_parameter1>> <<input_parameter2>>`***\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97f09f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data for the month:04 of the year:2022 to predict the mean riding time\n",
      "\n",
      "Predicting...\n",
      "\n",
      "The predicted mean riding time for the month:04 of the year:2022 is 12.83\n"
     ]
    }
   ],
   "source": [
    "# Mean Ride Duration Prediction for April 2022\n",
    "!docker run -it week4_deployment:latest 2022 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedfd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc72633",
   "metadata": {},
   "source": [
    "## Bonus: upload the result to the cloud (Not graded)\n",
    "\n",
    "Just printing the mean duration inside the docker image \n",
    "doesn't seem very practical. Typically, after creating the output \n",
    "faile, we upload it to the cloud storage.\n",
    "\n",
    "Modify your code to upload the parquet file to S3/GCS/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638df11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff2fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee51d99",
   "metadata": {},
   "source": [
    "## Publishing the image to dockerhub\n",
    "\n",
    "This is how we published the image to Docker hub:\n",
    "\n",
    "```bash\n",
    "docker build -t mlops-zoomcamp-model:v1 .\n",
    "docker tag mlops-zoomcamp-model:v1 svizor/zoomcamp-model:mlops-3.10.0-slim\n",
    "docker push svizor/zoomcamp-model:mlops-3.10.0-slim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5910eaef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/3)                                                         \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 342B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/svizor/zoomcamp-model:mlops-3.  0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (12/12) FINISHED                                              \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 342B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/svizor/zoomcamp-model:mlops-3.  0.0s\n",
      "\u001b[0m\u001b[34m => [1/7] FROM docker.io/svizor/zoomcamp-model:mlops-3.10.0-slim           0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 93B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/7] RUN pip install -U pip                                    0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/7] RUN pip install pipenv                                    0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/7] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/7] COPY [ Pipfile, Pipfile.lock, ./ ]                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/7] RUN pipenv install --system --deploy                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [7/7] COPY [q6-score.py, ./]                                    0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:e340f82146ca10f15855f4173f1a1522a2326a2f8bff3  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/mlops-zoomcamp-model-week4-deployment:  0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build -t mlops-zoomcamp-model-week4-deployment:latest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49cb8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag mlops-zoomcamp-model-week4-deployment:latest zatoichi/mlops-zoomcamp-model-week4-deployment:mlops-3.10.0-slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c1bd63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/zatoichi/mlops-zoomcamp-model-week4-deployment]\n",
      "\n",
      "\u001b[1B70a54087: Preparing \n",
      "\u001b[1B33802461: Preparing \n",
      "\u001b[1B856be0eb: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B84c2fefd: Preparing \n",
      "\u001b[1B4e5f9742: Preparing \n",
      "\u001b[1B53d86b70: Preparing \n",
      "\u001b[1Ba10cb66d: Preparing \n",
      "\u001b[6Bbf18a086: Preparing \n",
      "\u001b[1Bf6564658: Preparing \n",
      "\u001b[1B83285c91: Preparing \n",
      "\u001b[1Bf803d22a: Preparing \n",
      "\u001b[1B21b9bc30: Preparing \n",
      "\u001b[1Bae00a1e0: Preparing \n",
      "\u001b[1Be3a13052: Preparing \n",
      "\u001b[1B565baf43: Preparing \n",
      "\u001b[1B10ac81d3: Preparing \n",
      "\u001b[2B10ac81d3: Layer already exists \u001b[14A\u001b[2K\u001b[17A\u001b[2K\u001b[18A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2Kmlops-3.10.0-slim: digest: sha256:92bf9c5050185c7a284c131c3671c18a077c6e9468c506d2de7e8829e079e1a0 size: 4292\n"
     ]
    }
   ],
   "source": [
    "!docker push zatoichi/mlops-zoomcamp-model-week4-deployment:mlops-3.10.0-slim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d87f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b268a0",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://forms.gle/4tnqB5yGeMrTtKKa6\n",
    "* It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "* You can submit your answers multiple times. In this case, the last submission will be used for scoring.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is 26 June 2023 (Monday) 23:00 CEST. \n",
    "After that, the form will be closed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
